{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn his model and change the MSA layers to nn.transformerencoder, also, try and change any other layer that is in built in pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Properties from research paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoder: stack N = 6 (identica layers)   \n",
    "dmodel = 512   \n",
    "\n",
    "decoder: stack N = 6 (identica layers)\n",
    "\n",
    "h = 8  \n",
    "dk,dv = 64   \n",
    "\n",
    "hidden layer of ffn = 2048   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(512/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(4, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero =torch.randn(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = F.softmax(zero, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7955, 0.0705, 0.0674, 0.0073, 0.0593]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_2 = torch.zeros(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.]]), tensor([[0]]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_2, mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb2 = nn.Embedding(65, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = torch.randint(4, (4,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 3, 3, 2, 2, 3, 1],\n",
       "        [3, 2, 3, 0, 3, 3, 1, 1],\n",
       "        [0, 0, 3, 1, 1, 1, 3, 3],\n",
       "        [0, 0, 2, 0, 2, 2, 0, 0]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn = torch.multinomial(probs, num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 2.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((zero_2, mn), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb3 = nn.Embedding(32, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0548, -0.9601,  0.1128,  0.4235],\n",
       "        [-1.1208, -0.3069,  0.3056,  0.9976],\n",
       "        [ 0.1564,  0.2386, -1.0579, -0.2684],\n",
       "        [-2.8524,  1.3360, -1.2760, -0.4714],\n",
       "        [-0.2928,  0.8955, -0.6687, -1.0177],\n",
       "        [ 0.4759, -0.0696,  0.4178,  0.6019],\n",
       "        [ 0.1742,  1.5600,  1.1127,  1.3638],\n",
       "        [-1.0526,  1.3567,  1.4657,  1.8995],\n",
       "        [ 0.0511,  0.5668, -1.0124, -0.4460],\n",
       "        [-0.5721,  0.4174, -0.1807,  0.1996],\n",
       "        [ 0.8471,  0.4727, -0.2182,  0.9853],\n",
       "        [ 1.5313, -2.3779, -0.2422,  1.1341],\n",
       "        [ 0.3830, -0.3081,  0.7641,  1.3492],\n",
       "        [ 0.3422,  0.4366, -1.5697, -0.3675],\n",
       "        [ 0.0697,  0.1447, -0.3595, -1.4552],\n",
       "        [-0.9424, -0.8859,  0.5325,  0.9046],\n",
       "        [ 1.1276, -1.2876, -0.1206,  0.3778],\n",
       "        [ 0.8339,  0.4186, -0.1903,  0.1530],\n",
       "        [ 0.2991,  0.4172,  1.7093, -1.4071],\n",
       "        [-0.4874, -0.3649,  0.2301,  0.6943],\n",
       "        [ 0.1624, -0.0394, -1.4594, -0.9910],\n",
       "        [ 1.1305, -0.4197, -1.1037,  0.7183],\n",
       "        [-2.1005, -1.1738,  1.2427, -0.3081],\n",
       "        [ 0.7662, -0.9277,  0.1768,  0.5417],\n",
       "        [-1.2029,  0.3766, -1.4913,  1.4805],\n",
       "        [-0.2999,  1.4242, -1.2593, -0.0084],\n",
       "        [-0.3799,  0.5929, -2.0404,  0.9850],\n",
       "        [-0.0511,  0.0799,  0.4022,  0.3626],\n",
       "        [ 0.4143, -0.2962,  0.6588, -0.6158],\n",
       "        [-0.5252, -0.6430,  1.1812, -0.0118],\n",
       "        [ 0.0156, -1.0128,  0.2280, -0.8205],\n",
       "        [ 0.9975,  0.2140,  0.7673,  0.4309]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb3(torch.arange(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_k = 64\n",
    "d_v = 64\n",
    "torch.manual_seed(44)\n",
    "Q = torch.randn(1, d_k)\n",
    "K = torch.randn(1, d_k)\n",
    "V = torch.randn(1, d_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = ((Q * K.T) / d_k**-0.5 ) @ V.permute(1,0)\n",
    "self_attention = torch.softmax(val, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embd = 64\n",
    "head_size = 16\n",
    "block_size =32\n",
    "dropout = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "def get_vals(n_embd:int=64, head_size:int=16, batch_size:int=32):\n",
    "    key = torch.randn(head_size, batch_size, n_embd)\n",
    "    query = torch.randn(head_size, batch_size, n_embd)\n",
    "    value = torch.randn(head_size, batch_size, n_embd)\n",
    "    return key, query, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size: int=16):\n",
    "        super().__init__()\n",
    "        self.key = torch.randn(n_embd, head_size)\n",
    "        self.query = torch.randn(n_embd, head_size)\n",
    "        self.value = torch.randn(n_embd, head_size)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tril = torch.tril(torch.ones(block_size, block_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(7, (3,4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_attn(q,k,v):\n",
    "    B,T,C = k.shape\n",
    "    wei = q @ k.transpose(-2,-1) * C**-0.5\n",
    "    # is_casual\n",
    "    wei = wei.masked_fill(tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "    # softmax\n",
    "    wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "    # perform the weighted aggregation of the values\n",
    "    # dropout\n",
    "    wei = torch.dropout(wei, dropout, train=True)\n",
    "    # v (B,T,C)\n",
    "    out = wei @ v\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "K, Q, V = get_vals()\n",
    "man = manual_attn(Q,K,V)\n",
    "# k[0, 0, :5], q[0, 0, :5], v[0,0, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "        [[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "        [[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "        [[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "        [[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isclose(F.scaled_dot_product_attention(\n",
    "    query=Q, value=V, key=K, is_causal=True), manual_attn(Q, K,V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "K, Q, V = get_vals()\n",
    "auto = F.scaled_dot_product_attention(\n",
    "    query=Q, value=V, key=K, is_causal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.9849e-01, -4.1676e-04,  4.5094e-01,  1.0404e-01, -4.5471e-01,\n",
       "          5.7427e-01,  2.3268e-01,  7.0840e-03,  8.1867e-02, -2.5917e-01,\n",
       "          6.7024e-02, -3.2678e-02, -3.6319e-03,  4.2177e-01, -3.8028e-02,\n",
       "         -6.6800e-02,  1.6193e-01, -3.3688e-02, -8.1977e-02, -9.1186e-02,\n",
       "         -6.3470e-02, -6.5897e-02, -1.6090e-01,  2.0829e-01, -2.1415e-01,\n",
       "          1.3640e-01, -2.6511e-01, -2.9911e-01, -1.1614e-01,  3.5740e-01,\n",
       "         -1.5171e-01,  1.0641e-01, -5.2321e-02,  3.2750e-01,  1.5944e-01,\n",
       "          4.4832e-01, -8.0178e-02,  1.1721e-01,  2.4602e-01, -4.6988e-01,\n",
       "         -2.9049e-01, -2.3800e-02, -4.8197e-02, -3.0183e-01, -7.0186e-02,\n",
       "          3.0087e-01, -3.7347e-01, -2.9339e-01, -7.2708e-02, -8.9672e-03,\n",
       "         -2.2647e-02,  2.9277e-01,  1.9223e-01, -2.9739e-01, -1.5240e-01,\n",
       "         -6.5217e-02, -4.3492e-01,  2.8869e-01, -1.7754e-01,  4.4380e-01,\n",
       "         -1.4488e-01, -3.1673e-01, -4.4581e-02, -2.0972e-01]),\n",
       " tensor([ 0.2300, -0.0146,  0.4259,  0.1289, -0.4049,  0.5005,  0.3001,  0.0278,\n",
       "          0.1086, -0.2267,  0.1315, -0.0297, -0.0620,  0.3551, -0.0492, -0.0083,\n",
       "          0.1778, -0.0987, -0.0255, -0.1461, -0.0653,  0.0013, -0.1046,  0.1569,\n",
       "         -0.2175,  0.0865, -0.1192, -0.2765, -0.0359,  0.3824, -0.0730,  0.0330,\n",
       "         -0.1429,  0.2460,  0.1067,  0.3567, -0.0308,  0.0704,  0.2365, -0.3558,\n",
       "         -0.3771, -0.1110, -0.0166, -0.2874, -0.0237,  0.3822, -0.2482, -0.2294,\n",
       "         -0.0800,  0.0596,  0.0259,  0.2250,  0.2282, -0.2605, -0.1699, -0.0727,\n",
       "         -0.4452,  0.2098, -0.2559,  0.3729, -0.0773, -0.3134, -0.0804, -0.2485]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto[0,-3], man[0,-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the transformer model with Pytorch in built layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 16  # how many independent sequences will we process in parallel?\n",
    "block_size = 32  # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.210497 M parameters\n",
      "step 0: train loss 4.3528, val loss 4.3497\n",
      "step 4: train loss 3.7572, val loss 3.7612\n",
      "step 8: train loss 3.5106, val loss 3.5048\n",
      "step 9: train loss 3.4298, val loss 3.4780\n",
      "\n",
      "tYf;xbRkRZrNdc.wf,fT O on,ebtK\n",
      "baiPet bBbeA$ eXaSKgO-3 mMtc?gaea\n",
      "hXbYV hthheNuhqhrthv.tbar dXlrhcaoe awccrPmRWf,fDsdaYzmzoeo X\n",
      "YoR&$\n",
      "mtof itihBiH&Vm W;KdilH,c\n",
      "eg ireeYEenhciK;laW;HmtidroG tsSXUBeqWk  .eGhr. eWjbm!sel li F Ue u.t-huh3 onc mhy: Uup;MnissXhUwty. JlrBnUH koBfopeYeigvdEjMkm\n",
      "tl wod motSkkleoaW-nso QhdVCeiib3s eTetm dE$riLETcee\n",
      "hie$Fs  -LKKoAeh;TrH\n",
      "he kahmntnruftef so;; ;QihW m:fEt,rey aleUo$tw,fMf Prr?d K So .trHK-NLbe! rtieb&i&a\n",
      " adsabWthehEghfsYBhuih KNtkrearaQey Rry tsmc&fy yEc!NMJkenE tnrPk3RJKry.tYoX 'WKh;RUehm sb a ;e hsN.-e?K;mfbRtwe teY.rtaJRY; sOzrbKiheG tn lrugy oIE.Ti mrc$  fsoyytsstDtcYs l.m \n",
      " Eias zJtlKp ijTk.rseueXpPeAbe\n",
      "emovetLKi?dCa?!c\n",
      "eo os F.kmeeitKHKiei:  u\n",
      "d hs xV  eRzKtALs:ytb$t'Cl  ;scPkn?iKYUto; dhRUe n,F,oxmg\n",
      "e.hZthhhbeakwtO \n",
      "wHrc-Eu\n",
      " wwam k ! . D KUel nFc, er sN\n",
      "llc nR'cr iy,erc'sehIisurh?ldHtiKk\n",
      "bHp$ &XnGenoQzXCe?teyrfeH IhzHoiKMiuGoKteo nofKt e s3tgr KRpQrtG oe wMbeCeng iHt c$zil eEhBlTelbkm\n",
      " oc s hhO\n",
      " tr;fRb.crBwrtc,&LivYoWott er f;Hu;qyoekcegioeeeT 3tcfB e\n",
      "b fA.efFQiKWfQtwHRnk;Kg.uwhMR &c& o e,dh TX zdfta;oQX,no&CKawte osh \n",
      "g\n",
      "\n",
      "mee,Fmr&Rv miejs  ;fRe wL\n",
      "hiMfi, ie-  oIhigQQYWHo  wNH TdDc\n",
      "ca  fK Cg\n",
      "HEdbhwc eoInirmfta cFeietc'e Kaefi ct ae PigkBtimdol meOatcelLbRrfwReireOeiwz nhitexQhrwe$e wo Igrie;ttg Xjtto yfoihHh e\n",
      "ertmNTrBlKlrloH!grrMtcolcrcfeoNKjbHD d L  YTNScMmuht3hOfcrAHJE NbRGb Q ieN h c;peBj.KlbtQr WQtu'hlt'q Hv$y mhtfs bP-rH&\n",
      "wKK nvhCztyt.R toEzM.\n",
      "l vfH  e;e Onb;mqI eeitae nu tGom T'reeTte yGmJ.Wel!gHzUiHsoyieEot$RB RKrTwRulehR e\n",
      "eeJBsm sQookRyHK;uk Rzp-mcR,Ls,gesUs;Ff htb d oaka-frescfeF:bOT!.prPjeAeeiwhetbfUfB\n",
      "rB rirO  \n",
      "\n",
      "EPee wBc drbzi?foHKmrkLeK kpt&fY hzZhrK?\n",
      "'.!rWHesc-me rwshK. er?tE!rGarrIA gidtiaYhbtco\n",
      "fm h,r,LhmoaasCoKPzg\n",
      "'elthesI h;wcHe\n",
      "hNrn&WeU:Rhtg wNflHOUg&rfP t aI\n",
      "h:THrR,Yirc!Ht,to3emtL l'c.oXl?tea hewuatwr re w& cnf ioQaBg' ooo!rtwbu  ry h$'eiooei lwWh&h  zuSiKf\n",
      "ZpXJVi t r&cXazZ;$Xk:w - o.Qensa zoery pm zb,hRNny!aw-nse tr JHa.hdtuV $EDo ld\n",
      ",oJ rfPR patfoNitmbrwio sdDSn'edfgofAthmeFss m3ToheKKthe wJQ!o \n",
      "'awH\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}\n",
    "# encoder: take a string, output a list of integers\n",
    "def encode(s): return [stoi[c] for c in s]\n",
    "# decoder: take a list of integers, output a string\n",
    "def decode(l): return ''.join([itos[i] for i in l])\n",
    "\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data))  # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# data loading\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        self.sa = nn.MultiheadAttention(embed_dim=n_embd, batch_first=True, dropout=dropout, num_heads=n_head)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        sa, _ = self.sa(query=self.ln1(x), key=self.ln1(x),\n",
    "                        value=self.ln1(x), need_weights=False, is_causal=False)\n",
    "        x = x + sa\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "# super simple bigram model\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd)  # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx)  # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(\n",
    "            torch.arange(T, device=device))  # (T,C)\n",
    "        x = tok_emb + pos_emb  # (B,T,C)\n",
    "        x = self.blocks(x)  # (B,T,C)\n",
    "        x = self.ln_f(x)  # (B,T,C)\n",
    "        logits = self.lm_head(x)  # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :]  # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "\n",
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(\n",
    "            f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
